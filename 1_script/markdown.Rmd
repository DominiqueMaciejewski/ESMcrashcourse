---
title: "script"
output: html_document
date: "2023-11-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
# ---------------------------
# Script name:  ESM crashcourse - 
#               Workshop at VNOP-CAS research days 2023 (Utrecht, 16 November 2023)
#
# Author: Dr. Dominique Maciejewski
#
# Date Created: 2023-10-26
# 
# Copyright (c) Dominique Maciejewski, 
# License: CC BY 4.0 | Attribution 4.0 International 
# Email: d.f.maciejewski@tilburguniversity.edu
#
# In this very short crash-course, we will focus on two research questions
# 1) What is the momentary relation between rumination and negative emotion intensity (moment-level)? 
#    In other words: when individuals ruminate to a greater extent since the last beep, do they also experience 
#    more intense negative emotions? 
# 2) Does perceived stress at the person-level moderate this moment-level relation?
#    In other words: do inter-individual differences in perceived stress influence the strength of the
#    relation between rumination and negative emotion intensity (e.g., it is possible that people that 
#    experience more stress in general also ruminate more in response to negative emotions)? 

# Note: 
# Moment-level/within-person relations: How much people do deviate from their own mean?
# Person-level/between-person relations: How much people do differ from other people?
# This course is NOT comprehensive! For a great resource, part of which was used here, see
# 1) Myin-Germeys, I., & Kuppens, P. (Eds.). (2022) The open handbook of experience sampling methodology: 
# A step-by-step guide to designing, conducting, and analyzing ESM studies (2nd ed.). Leuven: Center for 
# Research on Experience Sampling and Ambulatory Methods Leuven. Available via: https://www.kuleuven.be/samenwerking/real/real-book
# 2) Tutorials by Penn State, available via https://quantdev.ssri.psu.edu/resources/intensive-longitudinal-data-analysis-experience-sampling-and-ema-data 


# Options ----------------------------------------------

options(scipen = 999)  # To prevent scientific notation
here::i_am("1_script/1_analyses_ESM_crashcourse.R") # Set location of script
sessionInfo() # For reproducibility (gives version numbers of packages)

# Library ----------------------------------------------

## install packages if needed
# install.packages("here")
# install.packages("readxl")
# install.packages("labelled")
# install.packages("ggplot2")
# install.packages("remotes")
# remotes::install_github("wviechtb/esmpack")
# install.packages("psych")
# install.packages("tidyr")
# install.packages("Hmisc")
# install.packages("misty")
# install.packages("nlme")
# install.packages("lmerTest")
# install.packages("sjPlot")

## load packages
library(here) # for relative paths (try avoiding absolute paths!)
library(readxl) # for reading excel files (for adding information from codebook) 
library(labelled) # for variable labels (for adding information from codebook) 
library(esmpack) # helps with data management of ESM data
library(dplyr) # for data wrangling
library(ggplot2) # for figures
library(psych) # for descriptives
library(tidyr) # for datawrangling
library(Hmisc) # for descriptives
library(misty) # for multilevel correlation
library(nlme) # for multilevel models
library(lmerTest) # so that p-values are given for multilevel models
library(sjPlot) # for nice display of multilevel model results


# Load in file ----------------------------------------------
data <- read.csv(here("0_data", "raw data","TYM_VNOP2023.csv"), header=TRUE, stringsAsFactors=FALSE)

# Functions ----------------------------------------------
# We will call in these specific functions later in the analyses

## Summary for violin plot
data_summary <- function(x) {
  m <- mean(x)
  ymin <- m-sd(x)
  ymax <- m+sd(x)
  return(c(y=m,ymin=ymin,ymax=ymax))
}

# Data inspection ----------------------------------------------
head(data) # inspecting first 6 rows of dataset

# Check non-missing in design data
check.nomiss(participant.ID, participant.ID, data=data)
check.nomiss(participant.ID, day, data=data)

# Check that perceived stress is time-invariant within subjects (i.e., does not vary within subjects)
check.timeinvar(DASS_Dep_subscale_sum_B, participant.ID, data=data, na.rm=FALSE)

# Check for duplicated beeps, examining the beep ID number
check.nodup(scheduledBeepId, participant.ID, data, out=1, na.rm=TRUE)
check.nodup(sentBeepId, participant.ID, data, out=1, na.rm=TRUE)

# Check range for items
psych::describe(data$n.em.int)
psych::describe(data$n.er.rum)
psych::describe(data$DASS_Dep_subscale_sum_B)

# Data cleaning ----------------------------------------------
# In the pre-registration for this project, I specified a number of conditions, where
# participants/beeps would be excluded, because they could indicate careless responding

## N participants & observations before exclusion ----
n_par_0 <- nsub(participant.ID, data) 
n_obs_0 <- sum(data$filledin == 1)

### Step 1: Exclude participants with zero variance  ------
data <- check.timeinvar(n.em.int, participant.ID, data, out = 3)
data <- check.timeinvar(n.er.rum, participant.ID, data, out = 3)

### Step 2: Total completion < 1 minute ------
data <- data %>%
  dplyr::filter(duration_sec_start_stop >=60 | is.na(duration_sec_start_stop)) 

## N participants & observations before exclusion ----
n_par_1 <- nsub(participant.ID, data) 
n_obs_1 <- sum(data$filledin == 1)

## N participants & observations excluded ----
n_par_0-n_par_1  # 1 participant excluded
n_obs_0-n_obs_1  # 33 observations excluded

## Centering ----------------------------------------------
# For the analyses later, variables will need to be centered
# For more information on centering see https://psyarxiv.com/xf2pw/ 

# 1) Person-center the time-varying variables -> subtract the individual mean from each score 
# 2) Grand-mean center the time-invariant variables -> subtract the group mean from each score 

### Person-mean centering -----------------------------
data$n.ev.int.c<-calc.mcent(n.ev.int, participant.ID, data=data)
data$n.er.rum.c<-calc.mcent(n.er.rum, participant.ID, data=data)

### Grand-mean centering -----------------------------
# calculate grandmean
groupmean <- aggregate(data$DASS_Dep_subscale_sum_B, 
                       list(data$participant.ID), 
                       FUN = mean, 
                       data = data, 
                       na.rm = TRUE)

mean_Dep <- mean(groupmean[,2], na.rm = TRUE)

# Grand-mean center
data <- data %>% 
  dplyr::mutate(Dep.c = DASS_Dep_subscale_sum_B-mean_Dep)

# Visualization ----------------------------------------------

## Time-series

### All participants
ggplot(data = data, aes(x = day, y = n.ev.int, group = participant.ID, color=factor(participant.ID))) +
  geom_line() +
  xlab("Day") + 
  ylab("Negative event intensity") + ylim(0,100) +
  scale_x_continuous(breaks=seq(0,61,by=10)) 

ggplot(data = data, aes(x = day, y = n.er.rum, group = participant.ID, color=factor(participant.ID))) +
  geom_line() +
  xlab("Day") + 
  ylab("Negative event intensity") + ylim(0,100) +
  scale_x_continuous(breaks=seq(0,61,by=10)) 


### Subgroup of 5 participants
# Negative event intensity
ggplot(data = data[which(data$participant.ID<=5),], aes(x = day, y = n.ev.int, group = participant.ID, color=factor(participant.ID))) +
  geom_point() + 
  geom_line(data=data[which(data$participant.ID<=5 & data$n.ev.int !="NA"),]) +
  xlab("Day") + 
  ylab("Negative event intensity") + ylim(0,100) +
  scale_x_continuous(breaks=seq(0,61,by=10)) 

# Rumination
ggplot(data = data[which(data$participant.ID<=5),], aes(x = day, y = n.er.rum, group = participant.ID, color=factor(participant.ID))) +
  geom_point() + 
  geom_line(data=data[which(data$participant.ID<=5 & data$n.er.rum !="NA"),]) +
  xlab("Day") + 
  ylab("Negative event intensity") + ylim(0,100) +
  scale_x_continuous(breaks=seq(0,61,by=10)) 

### Individual co-variation between negative event intensity and rumination 
# ID = 5
ggplot(data = subset(data, participant.ID == 5), aes(x=day), legend=TRUE) +
  geom_line(aes(x=day,y = n.ev.int), lty=1, size=1,colour="red") +
  geom_line(aes(x=day,y = n.er.rum), lty=2, size=1,colour="blue") +
  xlab("Day") + 
  ylab("Intensity") + ylim(0,100) +
  scale_x_continuous(breaks=seq(0,61,by=10)) +
  theme(legend.position="right") +
  ggtitle("Covariation between negative emotional intensity (red) & reappraisal (blue)") 

# ID = 20
ggplot(data = subset(data, participant.ID == 2), aes(x=day), legend=TRUE) +
  geom_line(aes(x=day,y = n.ev.int), lty=1, size=1,colour="red") +
  geom_line(aes(x=day,y = n.er.rum), lty=2, size=1,colour="blue") +
  xlab("Day") + 
  ylab("Intensity") + ylim(0,100) +
  scale_x_continuous(breaks=seq(0,61,by=10)) +
  theme(legend.position="right") +
  ggtitle("Covariation between negative emotional intensity (red) & reappraisal (blue)") 

### Boxplots
# reshape
data_sub<-data %>%
  dplyr::select("participant.ID","n.ev.int", "n.er.rum")

data_box <- data_sub %>% 
  pivot_longer(
    cols = 2:3,
    names_to = "variable",
    values_to = "value"
  )

# Boxplot
ggplot(data=data_box, aes(x=variable, y=value, fill = variable)) +
  geom_violin() + 
  stat_summary(fun.data=mean_sdl,  
               geom="pointrange", color="black") +
  scale_x_discrete(labels = c("Negative event intensity", "Rumination")) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +
  xlab("Study variables") + 
  ylab("Intensity") + 
  ylim(0,100)+
  theme(axis.title=element_text(size=14),
        axis.text=element_text(size=14),
        plot.title=element_text(size=14, hjust=.5)) +
  stat_summary(fun.data=data_summary)

# Descriptives ----------------------------------------------
## Time-varying event intensity and rumination
# For a descriptive statistics table, we could calculate the person-aggregate across all time-points and 
# report descriptive statistics on those

# Make a new dataset, aggregated across participants 
# Note that the Depression subscale is time-invariant anyway
data_M <- data %>%
  dplyr::group_by(participant.ID) %>%
  dplyr::summarize(
    across(c("n.ev.int", "n.er.rum", "DASS_Dep_subscale_sum_B"), ~mean(., na.rm = TRUE), .names = "imean_{.col}"))

## Within-person and between-person correlation (selecting only event and rumination)
multilevel.cor(data[, 8:9],
               cluster = data$participant.ID, 
               split = TRUE, sig = TRUE, 
               print = c("cor", "p"))

# Multilevel models ----------------------------------------------

## RQ1: What is the within-person association between negative event intensity and rumination?

fit.lme.rq1 <- lme(n.er.rum ~ 1 + n.ev.int.c + day, 
               random = ~ 1 + n.ev.int.c | participant.ID, 
               correlation = corAR1(),
               data = data, 
               na.action = na.exclude, 
               method = 'REML',
               control = lmeControl(opt='optim'))

tab_model(fit.lme.rq1)

## Plotting within-person association

# extract predicted relationship per individual
data$fit.lme.rq1 <- predict(fit.lme.rq1)

ggplot(data=data, aes(x=n.ev.int.c, y=fit.lme.rq1, group=factor(participant.ID), colour="gray"), legend=FALSE) +
  geom_smooth(method=lm, formula = y ~ x, se=FALSE, fullrange=FALSE, lty=1, size=.5, color="gray40") +
  geom_smooth(aes(group=1), method=lm, formula = y ~ x , se=FALSE, fullrange=FALSE, lty=1, size=2, color="blue") +
  xlab("Negative event intensity (person-centered)") + ylab("Rumination") +
  theme(axis.title=element_text(size=14),
        axis.text=element_text(size=10)) +
  ylim(0, 100)

## RQ2: Do inter-individual differences in depressive symptoms moderate is the 
#       within-person association between negative event intensity and rumination?

fit.lme.rq2 <- lme(n.er.rum ~ 1 + n.ev.int.c + day + Dep.c + n.ev.int.c:Dep.c, 
                   random = ~ 1 + n.ev.int.c | participant.ID, 
                   correlation = corAR1(),
                   data = data, 
                   na.action = na.exclude, 
                   method = 'REML',
                   control = lmeControl(opt='optim'))

tab_model(fit.lme.rq2)

```

